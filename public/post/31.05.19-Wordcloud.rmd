---
title: Wordclouds
author: ''
date: '2019-06-04'
categories:
  - R
  - wordcloud
tags:
  - R
  - Wordcloud
  - R Markdown
slug: 
lastmod: '2019-06-04T15:01:07+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

### TLDR
Wordclouds can be used to produce a neat summary of a text, even if they do sacrifice substance (information) for style. They can readily be produced in R.

---

### Summarising the content of an upcoming conference paper

There is an [R package dedicated to creating wordclouds](https://cran.r-project.org/web/packages/wordcloud/index.html), so I've started by loading this, along with the tidyverse.

```{r, include = TRUE, warning = FALSE, message = FALSE}
library(wordcloud); library(tidyverse)
```

The wordcloud package creates a graphic of words that appear in some specified text. The more times the word appears in the text, the larger it appears in the wordcloud. R can read text from a local file, as shown below, or from a website.

```{r, include = TRUE, eval = FALSE, warning = FALSE, message = FALSE}
# We can read a text file using 'readLines' and we can select a file interactively using 'file.choose'
# Both of these are Base R functions
paper <- readLines(file.choose())
```

```{r, include = FALSE}
paper <- readLines(con = 'C:/Users/domen/OneDrive/Documents/PhD/Conferences/IPW2019/Wordcloud/confPaper.txt')
```

Because of the way I've read my text, the 'paper' variable is currently as list of individual lines, as we can see when viewing one of its elements:
```{r, include = TRUE, warning = FALSE, message = FALSE}
print(paper[2])
```

As a result, I need to extract the individual words, which I've saved to a new variable:

```{r, include = TRUE, warning = FALSE, message = FALSE}
paperRows <- strsplit(paste(unlist(paper), collapse = " "), '\n')
paperWords <- unlist(strsplit(paste(unlist(paperRows), collapse = " "), ' '))
```

The next step is to create a dataframe that will eventually have two columns of interest to us: a list of words, and a count of the number of times they feature in the paper. I've set up an empty dataframe of the required size, and also added a check to identify small words (since I think words like 'the' are likely to feature a lot in the text, and I'd like the option of removing them from my wordcloud).

```{r, include = TRUE, warning = FALSE, message = FALSE}
paperWordData <- data.frame(word = c(rep(x = 0, times = length(paperWords))), 
                       count = c(rep(x = 0, times = length(paperWords))),
                       check = c(rep(x = 0, times = length(paperWords))))

paperWordData$word <- as.vector(paperWords)

maxLength <- 5

for (i in seq(from = 1, to = nrow(paperWordData), by = 1)){
  paperWordData$count[i] <- sum(paperWords == paperWords[i])
  if (nchar(paperWordData$word[i]) < maxLength) {
    paperWordData$check[i] <- 0
  } else {
    paperWordData$check[i] <- 1
  }
}
```

I'll then convert all words to lower case. Without this, if a word had begun with a capital letter (perhaps because it was starting a sentence) it would not have been included in the same count as instances of the same word beginning with a lower case letter.

```{r, include = TRUE, warning = FALSE, message = FALSE}
paperWordData$word <- tolower(paperWordData$word)
```

Time to make use of the filter that was previously set up to remove, short and uninteresting words.

```{r, include = TRUE, warning = FALSE, message = FALSE}
paperWordData <- unique(paperWordData) %>% 
  dplyr::filter(check == 1)
```

```{r, include = FALSE}
paperWordData <- paperWordData[-c(13,274),] %>% 
    dplyr::filter(!grepl('âˆ†k_th', word))
```

After reviewing the resultant wordcloud, I realised that my filter removing all words of length < `r maxLength` was not as comprehensive as I first thought. There were sti
ll a few words I didn't want to see, and I've resorted to doing this manually. Not very elegant, sadly.

```{r, include = TRUE, warning = FALSE, message = FALSE}
skippedWords <- c('which', 'there', 'these', 'therefore')

paperWordData <- paperWordData %>% 
  dplyr::filter(!grepl(paste(skippedWords, collapse='|'), word))
```

Finally, time to ask the wordcloud function to read and plot our data. There are some useful arguments to experiment with here:

 * **min.freq** and **max.words** set boundaries for how populated the wordcloud will be
 * **random.order** will put the largest word in the middle if set to FALSE
 * **rot.per** is the fraction of words that will be rotated in the graphic
 
Finally, the words are arranged stochastically somehow, and so for a repeatable graphic it is best to specify a seed value.

```{r, include = TRUE, warning = FALSE, message = FALSE}
set.seed(1008)
wordcloud(words = paperWordData$word, 
                     freq = paperWordData$count, 
                     min.freq = 3, max.words = 100, 
                     random.order = FALSE, rot.per = 0.25, 
                     colors = brewer.pal(n = 8, name = 'Dark2'))
```

If you're not familiar with the colour palettes, the below line will ask R to display them for you:
```{r, include = TRUE, warning = FALSE, message = FALSE, eval = FALSE}
RColorBrewer::display.brewer.all()
```

