<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>All Your Bayes</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>All Your Bayes</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-uk</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>All Your Bayes</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Consistent and Coherent Treatment of Uncertainties and Dependencies in Fatigue Crack Growth Calculations using Multi-Level Bayesian Models</title>
      <link>/publication/ress/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/publication/ress/</guid>
      <description>&lt;!---
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;



(&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
---&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Multi-Level Modelling for Improved Prediction of Corrosion Growth Rate</title>
      <link>/publication/omae/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/publication/omae/</guid>
      <description>&lt;!---
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;



(&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
---&gt;
</description>
    </item>
    
    <item>
      <title>Quantifying the Expected Value of Information</title>
      <link>/post/2020-08-03-expected-value-of-information.en/expected-value-of-information/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-08-03-expected-value-of-information.en/expected-value-of-information/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;We sometimes have the option to purchase additional information (like paying for an experiment to be performed, or for a report from an expert consultant) to help us in problems of decision making under uncertainty. Deciding whether or not such services are worthwhile is challenging - how do we know how to value some information before we get it? A powerful Bayesian procedure, which unfortunately goes by many names (such as preposterior decision analysis, multi-stage decision analysis, and Bayesian experimental design) allows us to quantify this expected value - in other words, it tells us &lt;em&gt;how much we should be willing to pay for information, before receiving it&lt;/em&gt;. This result will be context-dependent, and informed by whatever our state of knowledge happens to be at the time. This post is a largely non-technical outline of the key concepts of Value of Information (VoI) analysis.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;decision-making-under-uncertainty&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Decision Making under Uncertainty&lt;/h3&gt;
&lt;p&gt;Throughout industry, and even in our personal lives, we are required to make decisions without a perfect understanding of the problem. My PhD considers the problem of deciding whether or not risk mitigation measures were worth investing in, for structures in an uncertain state of damage. I quantified the expected value of inspection activities in this context, but this is quite a specific problem.&lt;/p&gt;
&lt;p&gt;For the purposes of this post, I’ll use the example of a garage (car repair shop if you don’t live in the UK) discussing some maintenance options for your car. I do not know enough about cars to talk about any specific problems, so imagine you have received the following generic statement from your mechanic about your car:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“This particular model of car, of this age, often develops a critical problem. We recommend replacing the component that wears out, because if you don’t, it will be much more expensive to fix after a breakdown.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Should you pay for the component to be replaced now? Or take your chances with a possible breakdown? Unsurprisingly, the expected optimal solution depends on the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How likely do you think it is that your car has this critical problem?&lt;/li&gt;
&lt;li&gt;How much will the repairs cost: (a) now? and (b) after a breakdown?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This problem can be visualised using an &lt;em&gt;influence diagram&lt;/em&gt;. The below uses the &lt;a href=&#34;http://rhugin.r-forge.r-project.org/&#34;&gt;&lt;code&gt;RHugin&lt;/code&gt; library&lt;/a&gt;, an &lt;code&gt;R&lt;/code&gt; API for the &lt;a href=&#34;https://www.hugin.com/&#34;&gt;Hugin software&lt;/a&gt;, although my first impressions of the &lt;a href=&#34;https://cran.r-project.org/web/packages/HydeNet/&#34;&gt;&lt;code&gt;HydeNet&lt;/code&gt; library&lt;/a&gt; are that it could be suitable alternative.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RHugin)

prior_analysis &amp;lt;- RHugin::read.rhd(&amp;#39;influence_diagram.net&amp;#39;)
plot.RHuginDomain(x = prior_analysis, what = &amp;#39;network&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-03-expected-value-of-information.en/2020-08-03-expected-value-of-information.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Elliptical nodes represent an uncertain outcome (the current condition of your car, and whether it will breakdown), rectangular nodes represent decisions (whether or not to pay for the repair) and diamond shaped nodes are the utilities (or costs) associated with each decision outcome. The arrows indicate dependency, for instance, the probability of a breakdown is dependent on whether or not the repair is performed (and the unknown condition of the car).&lt;/p&gt;
&lt;p&gt;If the above diagram looks confusing, it could alternatively be represented as a decision tree. However, for larger (more complex) decision making problems, I’ve found influence diagrams to be much more interpretable. This is because where each possible action or outcome would need it’s own ‘branch’ in a decision tree, they can all be represented within a table that is hidden behind every node in the influence diagram.&lt;/p&gt;
&lt;p&gt;If we had a &lt;em&gt;perfect&lt;/em&gt; understanding of the condition of our car, then we would know if it was going to breakdown and deciding whether this repair was worth doing would be easy. But we’re interested in solving more challenging problems, where it is sometimes a case of…&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/YVgzWgYgrmEdW/giphy.gif&#34; alt=&#34;Decision making under uncertainty.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Decision making under uncertainty.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We may be very unsure of the condition of the car. This implies that we consider there to be a significant chance that a repair is required (because we do not know enough to be confident that everything is OK). Even so, we need some sort of quantitative approach to allow us to make coherent decisions. The uncertainty in the problem can be described using probability, and the consequences can also be quantified.&lt;/p&gt;
&lt;p&gt;Firstly, after some online research (statements from the manufacturer, reviewers websites and forums), we’ve seen evidence that the problem that the mechanic described is real, and that 30% of cars like yours are affected:&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#rykfseaaqb .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rykfseaaqb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rykfseaaqb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rykfseaaqb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rykfseaaqb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rykfseaaqb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rykfseaaqb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rykfseaaqb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rykfseaaqb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rykfseaaqb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rykfseaaqb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rykfseaaqb .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#rykfseaaqb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rykfseaaqb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rykfseaaqb .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#rykfseaaqb .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#rykfseaaqb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rykfseaaqb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#rykfseaaqb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rykfseaaqb .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#rykfseaaqb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rykfseaaqb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rykfseaaqb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rykfseaaqb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rykfseaaqb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#rykfseaaqb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rykfseaaqb .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#rykfseaaqb .gt_left {
  text-align: left;
}

#rykfseaaqb .gt_center {
  text-align: center;
}

#rykfseaaqb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rykfseaaqb .gt_font_normal {
  font-weight: normal;
}

#rykfseaaqb .gt_font_bold {
  font-weight: bold;
}

#rykfseaaqb .gt_font_italic {
  font-style: italic;
}

#rykfseaaqb .gt_super {
  font-size: 65%;
}

#rykfseaaqb .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;rykfseaaqb&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;2&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;em&gt;Probabilities&lt;/em&gt; used in the decision analysis&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;2&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Condition&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_right&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Probability&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Pr(car damaged)&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;0.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Pr(car undamaged)&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;0.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Pr(car damaged | repair performed)&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_right&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;Secondly, after your best efforts to present yourself as a car aficionado, who can’t be fooled into paying an unfair price, the garage provides you with the following quotes:&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#sclgzjmrvw .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#sclgzjmrvw .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sclgzjmrvw .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#sclgzjmrvw .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#sclgzjmrvw .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sclgzjmrvw .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sclgzjmrvw .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#sclgzjmrvw .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#sclgzjmrvw .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#sclgzjmrvw .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#sclgzjmrvw .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#sclgzjmrvw .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#sclgzjmrvw .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#sclgzjmrvw .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#sclgzjmrvw .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#sclgzjmrvw .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#sclgzjmrvw .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#sclgzjmrvw .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#sclgzjmrvw .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sclgzjmrvw .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#sclgzjmrvw .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sclgzjmrvw .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#sclgzjmrvw .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sclgzjmrvw .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sclgzjmrvw .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#sclgzjmrvw .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sclgzjmrvw .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#sclgzjmrvw .gt_left {
  text-align: left;
}

#sclgzjmrvw .gt_center {
  text-align: center;
}

#sclgzjmrvw .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#sclgzjmrvw .gt_font_normal {
  font-weight: normal;
}

#sclgzjmrvw .gt_font_bold {
  font-weight: bold;
}

#sclgzjmrvw .gt_font_italic {
  font-style: italic;
}

#sclgzjmrvw .gt_super {
  font-size: 65%;
}

#sclgzjmrvw .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;sclgzjmrvw&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;2&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;em&gt;Costs&lt;/em&gt; used in the decision analysis&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;2&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Outcome&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Cost&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Perform Repair&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;$600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Breakdown&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;$3,000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/3orieTWiP0j908LiJa/giphy.gif&#34; alt=&#34;Bartering with mechanics.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Bartering with mechanics.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;By the way, the above values have been entirely made up (there is nothing special about them and the validity of this calculation does not depend on them).&lt;/p&gt;
&lt;p&gt;Here’s how you can populate the table of a node in a &lt;code&gt;Hugin&lt;/code&gt; influence diagram from within &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;repair_cost &amp;lt;- -600

repair_cost_table &amp;lt;- get.table(domain = prior_analysis, node = &amp;#39;Cost_Repair&amp;#39;)
repair_cost_table[&amp;#39;Utility&amp;#39;] &amp;lt;- c(0, repair_cost)

set.table(domain = prior_analysis, node = &amp;#39;Cost_Repair&amp;#39;, data = repair_cost_table)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then do the same to populate the other nodes (not shown here as it is more of the above), before asking &lt;code&gt;RHugin&lt;/code&gt; to evaluate the influence diagram.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RHugin::compile(object = prior_analysis)

RHugin::propagate(object = prior_analysis)
expected_costs &amp;lt;- get.utility(domain = prior_analysis, node = &amp;#39;Repair&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And our expected costs are shown for each of our decision options:&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#qmdomsscwm .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qmdomsscwm .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qmdomsscwm .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qmdomsscwm .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qmdomsscwm .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qmdomsscwm .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qmdomsscwm .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qmdomsscwm .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qmdomsscwm .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qmdomsscwm .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qmdomsscwm .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qmdomsscwm .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qmdomsscwm .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qmdomsscwm .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qmdomsscwm .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#qmdomsscwm .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#qmdomsscwm .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qmdomsscwm .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qmdomsscwm .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qmdomsscwm .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qmdomsscwm .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qmdomsscwm .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qmdomsscwm .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qmdomsscwm .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qmdomsscwm .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qmdomsscwm .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qmdomsscwm .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qmdomsscwm .gt_left {
  text-align: left;
}

#qmdomsscwm .gt_center {
  text-align: center;
}

#qmdomsscwm .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qmdomsscwm .gt_font_normal {
  font-weight: normal;
}

#qmdomsscwm .gt_font_bold {
  font-weight: bold;
}

#qmdomsscwm .gt_font_italic {
  font-style: italic;
}

#qmdomsscwm .gt_super {
  font-size: 65%;
}

#qmdomsscwm .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;qmdomsscwm&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Expected Cost&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Decision&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$900.00&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;No Repair&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$600.00&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Perform Repair&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;div id=&#34;a-quick-note-on-utility-theory&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;A Quick Note on Utility Theory&lt;/h4&gt;
&lt;p&gt;The optimal solutions in a decision analysis problem are those that correspond to a maximum expected pay-off (or a minimum expected cost). This mathematically coherent approach was first proposed by &lt;a href=&#34;https://www.amazon.co.uk/Economic-Behavior-Princeton-Classic-Editions/dp/0691130612&#34;&gt;John von Neumann and Oskar Morgenstern&lt;/a&gt;. However, it may not always be appropriate to map financial consequences of decision outcomes to a linear scale.&lt;/p&gt;
&lt;p&gt;Consider a possible cost of $30,000.&lt;/p&gt;
&lt;p&gt;Is this really twice as bad as an equally likely cost of $15,000? It depends.&lt;/p&gt;
&lt;p&gt;The higher cost, could have additional knock-on effects. It may require a loan, or some other expenditure to be deferred. If we are completing a decision analysis on behalf of a large company, then it could be reasonable to compare costs of this magnitude on a simple linear scale. However, if the decision maker was a small start-up, this assumption may not be helpful.&lt;/p&gt;
&lt;p&gt;As a result, we may need to transform monetary costs (or pay-off) onto a utility scale. The optimal decision is then that which is associated with the expected maximum utility. There is significant scientific literature on utility functions, but a concise discussion in the context of Bayesian decision theory is provided in &lt;a href=&#34;https://www.amazon.co.uk/Introduction-Statistical-Decision-Theory-Press/dp/026266206X&#34;&gt;the book from John Pratt, Howard Raiffa and Robert Schlaiffer&lt;/a&gt;. Some &lt;em&gt;default&lt;/em&gt; functions are available, but there is also the option of fitting a function from some points, where money vs. utility has been defined by the decision maker.&lt;/p&gt;
&lt;p&gt;An illustration of how the same amount of money could be valued differently by two parties is shown graphically below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-03-expected-value-of-information.en/2020-08-03-expected-value-of-information.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-value-of-information&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Value of Information&lt;/h3&gt;
&lt;p&gt;Now that we’ve set the scene, remember that the problem we are interested in, is:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How (and to what extent) can some additional information assist in the decision making process?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s extend the influence diagram, showing the option we have to perform a diagnostic test to improve our understanding of the condition of the car, before we decide whether to pay for the repair or not.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-03-expected-value-of-information.en/2020-08-03-expected-value-of-information.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the time being, I’ve not included a cost for the test, but I’ll come back to this point shortly. Now to compile the model…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RHugin::compile(object = prepost_analysis)

RHugin::propagate(object = prepost_analysis)
expected_costs &amp;lt;- get.utility(domain = prepost_analysis, node = &amp;#39;Test&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And our expected costs are shown for each of our decision options:&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#qjjijymkjy .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qjjijymkjy .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qjjijymkjy .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qjjijymkjy .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qjjijymkjy .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qjjijymkjy .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qjjijymkjy .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qjjijymkjy .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qjjijymkjy .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qjjijymkjy .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qjjijymkjy .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qjjijymkjy .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qjjijymkjy .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qjjijymkjy .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qjjijymkjy .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#qjjijymkjy .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#qjjijymkjy .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qjjijymkjy .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qjjijymkjy .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qjjijymkjy .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qjjijymkjy .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qjjijymkjy .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qjjijymkjy .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qjjijymkjy .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qjjijymkjy .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qjjijymkjy .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qjjijymkjy .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qjjijymkjy .gt_left {
  text-align: left;
}

#qjjijymkjy .gt_center {
  text-align: center;
}

#qjjijymkjy .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qjjijymkjy .gt_font_normal {
  font-weight: normal;
}

#qjjijymkjy .gt_font_bold {
  font-weight: bold;
}

#qjjijymkjy .gt_font_italic {
  font-style: italic;
}

#qjjijymkjy .gt_super {
  font-size: 65%;
}

#qjjijymkjy .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;qjjijymkjy&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Expected Cost&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Decision&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$180.00&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Perform Test&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$600.00&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;No Test&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;This tells us that our expected cost is reduced when we have more information (from the test) to support our decision of whether or not to pay for the repair. Uncertainty makes decision making more difficult, and so we will always benefit from improving our understanding of the problem.&lt;/p&gt;
&lt;p&gt;Specifically, the expected value of performing this test is equal to the difference between the expected costs, &lt;strong&gt;with&lt;/strong&gt; ($180.00)&lt;/p&gt;
&lt;p&gt;…and &lt;strong&gt;without&lt;/strong&gt; (-$600.00)…&lt;/p&gt;
&lt;p&gt;this information. This difference (our expected value of information) is equal to $420.00.&lt;/p&gt;
&lt;p&gt;As I mentioned earlier, I have not included a cost of the test in the second influence diagram. This means we can interpret this value as &lt;em&gt;the maximum amount we would be willing to pay for this test&lt;/em&gt;. If the garage offered the test for a fee less than $420.00, then we would be minimising expected costs by paying for the test. Otherwise, we would not expect the test to be worthwhile.&lt;/p&gt;
&lt;p&gt;Finally, what we have really calculated here, is the expected &lt;em&gt;Value of Perfect Information&lt;/em&gt;. This is because we are assuming this test is completely accurate, i.e. if the test indicates the car is damaged then we know for sure that it is. No test is ever perfect, and that means it won’t be as informative as we have assumed it to be here. As a result, the value of perfect information is really just an upper bound. Quickly identifying an upper bound can be very useful, but for cases where we need a better estimate we need to account for the imperfect features of the information we are considering buying.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;in-practice-the-value-of-imperfect-information&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;In Practice: The Value of &lt;em&gt;Imperfect&lt;/em&gt; Information&lt;/h3&gt;
&lt;p&gt;Imagine we now know a little bit more about the test that the garage is offering. We know that if it reports damage, there is a 10% chance that this is a mistake (sometimes referred to as a &lt;em&gt;false-positive&lt;/em&gt; error). Conversely, we have also learnt that this test misses damage (&lt;em&gt;false-negative&lt;/em&gt; error) 5% of the time. Since this will be less useful, than the perfect information that we considered above, it will not be any more valuable.&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#gnjfltntqk .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#gnjfltntqk .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#gnjfltntqk .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#gnjfltntqk .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#gnjfltntqk .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#gnjfltntqk .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#gnjfltntqk .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#gnjfltntqk .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#gnjfltntqk .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#gnjfltntqk .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#gnjfltntqk .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#gnjfltntqk .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#gnjfltntqk .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#gnjfltntqk .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#gnjfltntqk .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#gnjfltntqk .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#gnjfltntqk .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#gnjfltntqk .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#gnjfltntqk .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#gnjfltntqk .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#gnjfltntqk .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#gnjfltntqk .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#gnjfltntqk .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#gnjfltntqk .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#gnjfltntqk .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#gnjfltntqk .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#gnjfltntqk .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#gnjfltntqk .gt_left {
  text-align: left;
}

#gnjfltntqk .gt_center {
  text-align: center;
}

#gnjfltntqk .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#gnjfltntqk .gt_font_normal {
  font-weight: normal;
}

#gnjfltntqk .gt_font_bold {
  font-weight: bold;
}

#gnjfltntqk .gt_font_italic {
  font-style: italic;
}

#gnjfltntqk .gt_super {
  font-size: 65%;
}

#gnjfltntqk .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;gnjfltntqk&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Expected Cost&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Decision&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$257.89&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;Perform Test&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;-$600.00&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34; style=&#34;background-color: #FFFFFF;&#34;&gt;No Test&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;Based on these new expected utilities, the expected value of this imperfect test is $342.11. We can use this calculation to perform a sensitivity analysis, showing how (for example) the false negative error rate influences the expected value of the test:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-08-03-expected-value-of-information.en/2020-08-03-expected-value-of-information.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, tests that are more likely to miss the damage are not worth as much to us. The discrepancy between the value of the perfect and imperfect tests without a false-negative error (&lt;span class=&#34;math inline&#34;&gt;\(\Pr(Pass\;Test \mid Car\;damaged) = 0\)&lt;/span&gt;), is due to the false-positive error of 10%, which I left unchanged.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;more-realistic-models-working-on-continuous-scales&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;More Realistic Models (Working on Continuous Scales)&lt;/h3&gt;
&lt;p&gt;By discretising uncertain outcomes, we simplify the analysis we need to do to identify our expected optimal decisions. However, this may be an inaccurate representation of the true problem. Predicting whether or not a car will breakdown based on the condition of a component may itself require a reliability assessment (probabilistic calculation). Similarly, it may not be appropriate to represent features of the diagnostic test on a discrete scale either. For instance, the probability of missing damage may be a function of the extent of the damage, i.e. it is generally less likely that greater deterioration is missed. The measurements may also need to be a continuous scale, which should account for precision and possible bias.&lt;/p&gt;
&lt;div id=&#34;what-challenges-does-this-introduce&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;What challenges does this introduce?&lt;/h4&gt;
&lt;p&gt;Essentially, the calculations become more time-consuming. Moving from discrete to continuous probability functions requires either neat mathematical methods, or many more calculations. In the case of the latter, we would repeat the above calculation for each sample that we draw from a probability distribution. When estimating very small probabilities, a lot of samples are required, and these calculations can take a long time to run without efficiency boosting methods such as &lt;em&gt;importance sampling&lt;/em&gt;. I plan to write a future post showing some examples of this type of thing soon. I’ve not included a more realistic example here, since this is just a conceptual introduction, but you can see a full example in &lt;a href=&#34;https://www.allyourbayes.com/publication/cees/&#34;&gt;my recent paper&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-of-key-principles-final-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summary of Key Principles &amp;amp; Final Thoughts&lt;/h3&gt;
&lt;p&gt;Here are the most important ideas to remember from the above:&lt;/p&gt;
&lt;p&gt;The act of collecting information (such as the the diagnostic test on the car) does not &lt;em&gt;itself&lt;/em&gt; reduce risk. What it does do, is allow us to re-evaluate the options available to us with a better understanding of the problem. Therefore…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;to quantify the value of information, you need to relate it to the improved decision making that it facilitates.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is exactly what we have done in this example. We have compared our expected costs with and without the diagnostic test, allowing us to quantify the expected benefit of performing the test, in terms of money. This benefit arises from the simplification of the decision problem of whether to pay for the repair.&lt;/p&gt;
&lt;p&gt;More generally, the act of collecting information, does not prevent costly failures in our systems. In the episode of &lt;em&gt;The Simpsons&lt;/em&gt;, &lt;a href=&#34;https://simpsons.fandom.com/wiki/Homer%27s_Enemy&#34;&gt;Homer’s Enemy&lt;/a&gt; Bart buys an old factory at an auction. It’s in terrible condition, so he hires Milhouse as a night watchman, so that they can keep from collapsing and continue to play in it. As shown below, Milhouse carries out his watchman duties….&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/3orif90qwQCb9H0Uo0/giphy.gif&#34; alt=&#34;Monitoring, then not acting - the Milhouse approach.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Monitoring, then not acting - the Milhouse approach.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is the equivalent of paying for information just for the sake of it, like installing unnecessary sensors on a structure. An evaluation of inspection, monitoring, or testing options should be done in the context of the underlying decision problem that you are trying to solve. I don’t think this is a straightforward idea - but hopefully this discussion has demonstrated the concept.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The value of information is context dependent.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes, more expensive, higher quality information is worth paying for. Sometimes it isn’t. When we already have a good idea of what we will find, or if it doesn’t really matter what we find - then we may get little to no value from additional information. When there is a lot of uncertainty in a problem and it pays to know exactly what’s going on, it may be worth spending big for high quality data.&lt;/p&gt;
&lt;p&gt;I’d suggest that it’s only really at these extremes where we would intuitively know our best course of action.&lt;/p&gt;
&lt;div id=&#34;uncertainty-on-top-of-uncertainty-on-top-of&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Uncertainty on top of uncertainty on top of…&lt;/h4&gt;
&lt;p&gt;The value of the diagnostic test on the car is dependent on the initial (prior) probability that the car was damaged. So the expected value of some data is based on what we think it will say? You may be understandably sceptical of what might seem fragile foundations of this method, but allow me to convince you otherwise:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/vz38u37GjVWE0/giphy.gif&#34; alt=&#34;Sceptical?&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Sceptical?&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Remember - we are using this method to tackle problems of decision making under uncertainty and we are representing that uncertainty with probability. We are not doing this to complicate things. Uncertainty exists, whether we choose to account for it or not. We are can identify the &lt;em&gt;expected&lt;/em&gt; best course of action, on the basis of our current partial understanding of the problem. If we knew more, we could do better, but we need to work with what we’ve got.&lt;/p&gt;
&lt;p&gt;Also, when an organisation or an individual makes a difficult decision without thinking about it formally like we have here, then this entire process is just implicit. They are basing their decision on something, but we don’t know what exactly. This makes it very difficult to change any particular aspect of their decision making process, and for problems that do not have intuitive answers, relying on a &lt;em&gt;gut feeling&lt;/em&gt; will not always be helpful.&lt;/p&gt;
&lt;p&gt;Now, if we see the result of a value of information calculation and it doesn’t feel right, this could mean a few things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The problem may not be intuitive.&lt;/strong&gt; Our feeling for what the result &lt;em&gt;should&lt;/em&gt; be is actually overlooking some complexity. If we suspect this is the case, then maybe it is better to trust the result. Since it can easily be documented, then each element can be critiqued and re-visited whenever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We’ve not included enough expert judgement.&lt;/strong&gt; Fortunately, this can easily be fixed as Bayesian methods are happy to accommodate prior information. In &lt;a href=&#34;https://www.allyourbayes.com/post/2020-02-14-bayesian-logistic-regression-with-stan/&#34;&gt;my post on Bayesian logistic regression&lt;/a&gt; I showed how prior predictive simulation can help identify sensible priors, even in more complicated Bayesian models. A great feature of this, is that the expert knowledge that goes in, is part of the model. This is much smarter than throwing out a calculation that an expert doesn’t agree with, or discussing &lt;em&gt;experience&lt;/em&gt;, &lt;em&gt;judgement&lt;/em&gt;, or &lt;em&gt;expertise&lt;/em&gt; as separate, unrelated topics.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;are-there-real-world-applications-or-is-this-all-academic&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Are there Real World Applications? Or is this all Academic?&lt;/h4&gt;
&lt;p&gt;When would anyone ever actually go to the effort of evaluating a decision in this way? (Other than academics who need to publish papers).&lt;/p&gt;
&lt;p&gt;The idea of comparing expected utility with and without additional information was first proposed by &lt;a href=&#34;https://www.semanticscholar.org/paper/Applied-Statistical-Decision-Theory.-Minton-Raiffa/b3b885eba933831514ea3bc7ec289243a81176e9?p2df&#34;&gt;Raiffa &amp;amp; Schlaiffer in the 1960’s&lt;/a&gt;, but the computational tools available to us now, means that there are more real-world examples that can be modelled in this way.&lt;/p&gt;
&lt;p&gt;Broadly speaking kind of calculation is worthwhile when there is enough risk associated with a decision. In designing expensive experiments, where you need to make each measurement count, then identifying the points where the expected value of data will be the most (in the context of the problem you are trying to solve) could be very helpful in not wasting your budget.&lt;/p&gt;
&lt;p&gt;The method has been demonstrated in the context of &lt;a href=&#34;https://www.convoi-group.org/&#34;&gt;medical decision making&lt;/a&gt; and in engineering, specifically the &lt;a href=&#34;https://www.cost-tu1402.eu/&#34;&gt;placement of sensors for structural health monitoring&lt;/a&gt;. However, it is really a generic framework, and I’m sure you can imagine many more applications, which are outside my current domain of knowledge - please send me a message if any that come to mind.&lt;/p&gt;
&lt;p&gt;Academic presentation of decision analysis uses mathematical language, and this is helpful when explaining more complex application of these principles in a concise way. However, an appreciation for the fundamentals of what a value of information calculation is trying to achieve, and how it works can help stakeholders contribute to, and improve the process. I personally believe that this is potentially, an extremely powerful tool in decision support.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Maximum Likelihood Estimation</title>
      <link>/post/2020-07-28-maximum-likelihood-estimation/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-07-28-maximum-likelihood-estimation/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;Maximum Likelihood Estimation (MLE) is one method of inferring model parameters. This post aims to give an intuitive explanation of MLE, discussing why it is so useful (simplicity and availability in software) as well as where it is limited (point estimates are not as informative as Bayesian estimates, which are also shown for comparison).&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Distribution parameters describe the shape of a distribution function. A normal (Gaussian) distribution is characterised based on it’s mean, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Increasing the mean &lt;em&gt;shifts&lt;/em&gt; the distribution to be centered at a larger value and increasing the standard deviation &lt;em&gt;stretches&lt;/em&gt; the function to give larger values further away from the mean. When we approximate some uncertain data with a distribution function, we are interested in estimating the distribution parameters that are most consistent with the data.&lt;/p&gt;
&lt;p&gt;The likelihood, &lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;, of some data, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, is shown below. Where &lt;span class=&#34;math inline&#34;&gt;\(f(\theta)\)&lt;/span&gt; is the function that has been proposed to explain the data, and &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; are the parameter(s) that characterise that function.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
L = \displaystyle\prod_{i=1}^{N} f(z_{i} \mid \theta)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Likelihood values (and therefore also the product of many likelihood values) can be very small, so small that they cause problems for software. Therefore it’s usually more convenient to work with log-likelihoods instead. Taking the logarithm is applying a &lt;em&gt;monotonically increasing&lt;/em&gt; function. This means if one function has a higher sample likelihood than another, then it will also have a higher log-likelihood. Also, the location of maximum log-likelihood will be also be the location of the maximum likelihood.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\log{(L)} = \displaystyle\sum_{i=1}^{N} f(z_{i} \mid \theta)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The distribution parameters that maximise the log-likelihood function, &lt;span class=&#34;math inline&#34;&gt;\(\theta^{*}\)&lt;/span&gt;, are those that correspond to the maximum sample likelihood.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\theta^{*} = arg \max_{\theta} \bigg[ \log{(L)} \bigg]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Below, two different normal distributions are proposed to describe a pair of observations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs &amp;lt;- c(0, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The red distribution has a mean value of &lt;code&gt;1&lt;/code&gt; and a standard deviation of &lt;code&gt;2&lt;/code&gt;. The green distribution has a mean value of &lt;code&gt;2&lt;/code&gt; and a standard deviation of &lt;code&gt;1&lt;/code&gt; and so is centered further to the right, and is less dispersed (less stretched out). The red arrows point to the likelihood values of the data associated with the red distribution, and the green arrows indicate the likelihood of the same data with respect to the green function. The first data point, 0 is more likely to have been generated by the red function, and the second data point, 3 is more likely to have been generated by the green function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-07-28-maximum-likelihood-estimation_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can evaluate the log-likelihood and compare the two functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(log(dnorm(x = obs, mean = 1, sd = 2))) # Red function
## [1] -3.849171

sum(log(dnorm(x = obs, mean = 2, sd = 1))) # Green function
## [1] -4.337877&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As shown above, the red distribution has a higher log-likelihood (and therefore also a higher likelihood) than the green function, with respect to the 2 data points. The above graph suggests that this is driven by the first data point , 0 being significantly more consistent with the red function. The below example looks at how a distribution parameter that maximises a sample likelihood could be identified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mle-for-an-exponential-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;MLE for an Exponential Distribution&lt;/h3&gt;
&lt;p&gt;The exponential distribution is characterised by a single parameter, it’s rate &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(z, \lambda) = \lambda \cdot \exp^{- \lambda \cdot z}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is a widely used distribution, as it is a Maximum Entropy (MaxEnt) solution. If some unknown parameters is known to be positive, with a fixed mean, then the function that best conveys this (and only this) information is the exponential distribution. I plan to write a future post about the MaxEnt principle, as it is deeply linked to Bayesian statistics. The expectation (mean), &lt;span class=&#34;math inline&#34;&gt;\(E[y]\)&lt;/span&gt; and variance, &lt;span class=&#34;math inline&#34;&gt;\(Var[y]\)&lt;/span&gt; of an exponentially distributed parameter, &lt;span class=&#34;math inline&#34;&gt;\(y \sim exp(\lambda)\)&lt;/span&gt; are shown below:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E[y] = \lambda^{-1}, \; Var[y] = \lambda^{-2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Simulating some example data…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_samples &amp;lt;- 25; true_rate &amp;lt;- 1; set.seed(1)

exp_samples &amp;lt;- rexp(n = n_samples,
                    rate = true_rate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code, 25 independent random samples have been taken from an exponential distribution with a mean of 1, using &lt;code&gt;rexp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Below, for various proposed &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values, the log-likelihood (&lt;code&gt;log(dexp())&lt;/code&gt;) of the sample is evaluated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
exp_lik_df &amp;lt;- data.frame(rate = double(), 
                         lik = double())

for (i in seq(from = 0.2, to = 2, by = 0.2)){
  
  exp_lik_df &amp;lt;- rbind(exp_lik_df, 
                      data.frame(rate = i,
                                 log_lik = sum(log(
                                   dexp(x = exp_samples,
                                        rate = i)))))
  
}

max_log_lik &amp;lt;- exp_lik_df[which.max(x = exp_lik_df$log_lik),]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, &lt;code&gt;max_log_lik&lt;/code&gt; finds which of the proposed &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values is associated with the highest log-likelihood.&lt;/p&gt;
&lt;p&gt;We can print out the data frame that has just been created and check that the maximum has been correctly identified.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(exp_lik_df)
##    rate   log_lik
## 1   0.2 -45.38774
## 2   0.4 -33.21086
## 3   0.6 -28.22602
## 4   0.8 -26.18577
## 5   1.0 -25.75897
## 6   1.2 -26.35273
## 7   1.4 -27.65076
## 8   1.6 -29.46427
## 9   1.8 -31.67149
## 10  2.0 -34.18927

print(max_log_lik)
##   rate   log_lik
## 5    1 -25.75897&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The below plot shows how the sample log-likelihood varies for different values of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;. It also shows the shape of the exponential distribution associated with the lowest (top-left), optimal (top-centre) and highest (top-right) values of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; considered in these iterations:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-07-28-maximum-likelihood-estimation_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;mle-in-practice-software-libraries&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;MLE in Practice: Software Libraries&lt;/h4&gt;
&lt;p&gt;In practice there are many software packages that quickly and conveniently automate MLE. Here are some useful examples…&lt;/p&gt;
&lt;p&gt;Firstly, using the &lt;code&gt;fitdistrplus&lt;/code&gt; library in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
library(fitdistrplus)

sample_data &amp;lt;- exp_samples

rate_fit_R &amp;lt;- fitdist(data = sample_data, 
                      distr = &amp;#39;exp&amp;#39;, 
                      method = &amp;#39;mle&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although I have specified &lt;code&gt;mle&lt;/code&gt; (maximum likelihood estimation) as the method that I would like &lt;code&gt;R&lt;/code&gt; to use here, it is already the default argument and so we didn’t need to include it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; provides us with an list of plenty of useful information, including:
- the original data
- the size of the dataset
- the co-variance matrix (especially useful if we are estimating multiple parameters)
- some measures of well the parameters were estimated&lt;/p&gt;
&lt;p&gt;You can explore these using &lt;code&gt;$&lt;/code&gt; to check the additional information available.&lt;/p&gt;
&lt;p&gt;We can take advantage of this to extract the estimated parameter value and the corresponding log-likelihood:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rate_fit_R$estimate
##      rate 
## 0.9705356
rate_fit_R$loglik
## [1] -25.74768&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, with &lt;code&gt;SciPy&lt;/code&gt; in &lt;code&gt;Python&lt;/code&gt; (using the same data):&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import scipy.stats as stats

sample_data = r.exp_samples

rate_fit_py = stats.expon.fit(data = sample_data, floc = 0)
rate = (rate_fit_py[1])**-1

print(rate)
## 0.9705355729681481&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though we did not specify MLE as a method, the &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html&#34;&gt;online documentation&lt;/a&gt; indicates this is what the function uses.&lt;/p&gt;
&lt;p&gt;We can also calculate the log-likelihood associated with this estimate using &lt;code&gt;NumPy&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np

np.sum(np.log(stats.expon.pdf(x = sample_data, 
                              scale = rate_fit_py[1])))
## -25.747680569393435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve shown that values obtained from &lt;code&gt;Python&lt;/code&gt; match those from &lt;code&gt;R&lt;/code&gt;, so (as usual) both approaches will work out.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;method&lt;/code&gt; argument in &lt;code&gt;R&lt;/code&gt;’s &lt;code&gt;fitdistrplus::fitdist()&lt;/code&gt; function also accepts &lt;code&gt;mme&lt;/code&gt; (moment matching estimation) and &lt;code&gt;qme&lt;/code&gt; (quantile matching estimation), but remember that MLE is the default. One useful feature of MLE, is that (with sufficient data), parameter estimates can be approximated as normally distributed, with the covariance matrix (for all of the parameters being estimated) equal to the inverse of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Hessian_matrix&#34;&gt;Hessian matrix&lt;/a&gt; of the likelihood function.&lt;/p&gt;
&lt;p&gt;However, MLE is primarily used as a point estimate solution and the information contained in a single value will always be limited. Likelihoods will not necessarily be symmetrically dispersed around the point of maximum likelihood. We may be interested in the full distribution of credible parameter values, so that we can perform sensitivity analyses and understand the possible outcomes or optimal decisions associated with particular credible intervals. See below for a proposed approach for overcoming these limitations.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations-or-how-to-do-better-with-bayesian-methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Limitations (or ‘How to do better with Bayesian methods’)&lt;/h3&gt;
&lt;p&gt;An intuitive method for quantifying this &lt;em&gt;epistemic&lt;/em&gt; (statistical) uncertainty in parameter estimation is Bayesian inference. This removes requirements for a sufficient sample size, while providing more information (a full &lt;em&gt;posterior&lt;/em&gt; distribution) of credible values for each parameter. If multiple parameters are being simultaneously estimated, then the posterior distribution will be a joint probabilistic model of all parameters, accounting for any inter-dependencies too. Finally, it also provides the opportunity to build in prior knowledge, which we may have available, before evaluating the data.&lt;/p&gt;
&lt;p&gt;Take it from &lt;code&gt;Stan&lt;/code&gt; himself:
&lt;img src=&#34;https://media.giphy.com/media/3o6Zt7NrhNRgdFkBeU/source.gif&#34; alt=&#34;Stan’s advice&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Returning to the challenge of estimating the rate parameter for an exponential model, based on the same 25 observations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(exp_samples)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1061  0.4361  0.7552  1.0304  1.2296  4.4239&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will now consider a Bayesian approach, by writing a &lt;code&gt;Stan&lt;/code&gt; file that describes this exponential model:&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data {

  int &amp;lt;lower = 0&amp;gt; N; // Defining the number of observations
  vector &amp;lt;lower = 0&amp;gt; [N] samples; // A vector containing the observations
  
}

parameters {
  
  // The (unobserved) model parameter that we want to estimate
  real &amp;lt;lower = 0&amp;gt; rate;

}

model {

  // An exponential model, which we are proposing to describe the data
  samples ~ exponential(rate);
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with &lt;a href=&#34;https://www.allyourbayes.com/post/bayesian-regression-models-with-stan/&#34;&gt;previous examples&lt;/a&gt; on this blog, data can be pre-processed, and results can be extracted using the &lt;code&gt;rstan&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)

exp_posterior_samples &amp;lt;- sampling(object = exp_model,
                                  data = list(N = n_samples, 
                                              samples = exp_samples),
                                  seed = 1008)
## 
## SAMPLING FOR MODEL &amp;#39;5328d75314acb3313bc7fa418eeb08c2&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.037 seconds (Warm-up)
## Chain 1:                0.034 seconds (Sampling)
## Chain 1:                0.071 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;5328d75314acb3313bc7fa418eeb08c2&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.048 seconds (Warm-up)
## Chain 2:                0.029 seconds (Sampling)
## Chain 2:                0.077 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;5328d75314acb3313bc7fa418eeb08c2&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.04 seconds (Warm-up)
## Chain 3:                0.032 seconds (Sampling)
## Chain 3:                0.072 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;5328d75314acb3313bc7fa418eeb08c2&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.026 seconds (Warm-up)
## Chain 4:                0.024 seconds (Sampling)
## Chain 4:                0.05 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: We have not specified a prior model for the rate parameter. &lt;code&gt;Stan&lt;/code&gt; responds to this by setting what is known as an &lt;em&gt;improper&lt;/em&gt; prior (a uniform distribution bounded only by any upper and lower limits that were listed when the parameter was declared). For real-world problems, there are many reasons to avoid uniform priors. Partly because they are no longer ‘non-informative’ when there are transformations, such as in generalised linear models, and partly because there will always be some prior information to help direct you towards more credible outcomes. However, this data has been introduced without any context and by using uniform priors, we should be able to recover the same maximum likelihood estimate as the non-Bayesian approaches above.&lt;/p&gt;
&lt;p&gt;Extracting the results from our model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmcmc)

extracted_samples &amp;lt;- ggs(S = exp_posterior_samples)

head(x = extracted_samples, n = 5)
## # A tibble: 5 x 4
##   Iteration Chain Parameter value
##       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;     &amp;lt;dbl&amp;gt;
## 1         1     1 rate      0.614
## 2         2     1 rate      0.710
## 3         3     1 rate      0.783
## 4         4     1 rate      1.00 
## 5         5     1 rate      1.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use this data to visualise the uncertainty in our estimate of the rate parameter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = extracted_samples %&amp;gt;% 
         dplyr::filter(Parameter == &amp;#39;rate&amp;#39;))+
  geom_density(mapping = aes(x = value, 
                             y = ..density..), 
               fill = &amp;#39;purple4&amp;#39;, alpha = 0.2)+
  geom_vline(aes(lty = &amp;#39;MLE solution&amp;#39;, 
                 xintercept = rate_fit_R$estimate))+
  scale_linetype_manual(values = c(2))+
  scale_x_continuous(name = &amp;#39;Rate Parameter&amp;#39;)+
  scale_y_continuous(name = &amp;#39;Posterior Likelihood&amp;#39;)+
  theme_ddf_light()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-07-28-maximum-likelihood-estimation_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can use the full posterior distribution to identify the maximum posterior likelihood (which matches the MLE value for this simple example, since we have used an improper prior). However, we can also calculate credible intervals, or the probability of the parameter exceeding any value that may be of interest to us.&lt;/p&gt;
&lt;p&gt;This distribution includes the statistical uncertainty due to the limited sample size. As more data is collected, we generally see a reduction in uncertainty. Based on a similar principle, if we had also have included some information in the form of a prior model (even if it was only weakly informative), this would also serve to reduce this uncertainty.&lt;/p&gt;
&lt;p&gt;Finally, we can also sample from the posterior distribution to plot predictions on a more meaningful outcome scale (where each green line represents an exponential model associated with a single sample from the posterior distribution of the rate parameter):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-07-28-maximum-likelihood-estimation_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why Go Bayesian?</title>
      <link>/post/2020-03-24-why-go-bayesian/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-03-24-why-go-bayesian/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;This post is intended to be a high-level discussion of the merits and challenges of applied Bayesian statistics. It is intended to help the reader answer: &lt;em&gt;Is it worth me learning Bayesian statistics?&lt;/em&gt; or &lt;em&gt;Should I look into using Bayesian statistics in my project?&lt;/em&gt; Maths, code and technical details have all been left out.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;bayes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bayes&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/TJBbXQooivUNq/giphy.gif&#34; alt=&#34;Bayes&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Bayes&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Firstly, Bayesian…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Statistics&lt;/li&gt;
&lt;li&gt;Inference&lt;/li&gt;
&lt;li&gt;Modelling&lt;/li&gt;
&lt;li&gt;Updating&lt;/li&gt;
&lt;li&gt;Data Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…can be considered the same thing (certainly for the purposes of this post): &lt;strong&gt;the application of Bayes theorem to quantify uncertainty&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So Bayesian statistics may be of interest to you if you are dealing with a problem associated with uncertainty - either due to some underlying variability, or due to limitations of your data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-does-a-bayesian-approach-provide&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What does a Bayesian Approach Provide?&lt;/h3&gt;
&lt;p&gt;Bayesian statistics is not the only way to account for uncertainty in calculations. The below points describe what a Bayesian approach offers, that others don’t. Note that I am only really discussing methods involving probability here, though &lt;a href=&#34;https://www.springer.com/gp/book/9783540402947&#34;&gt;alternative approaches are available&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;intuitive-interpretation-of-results&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Intuitive Interpretation of Results&lt;/h4&gt;
&lt;p&gt;The outcome of a Bayesian model is a posterior distribution. This describes the joint uncertainty in all the parameters you are trying to estimate. This can be used to describe uncertainty in a prediction for some new input data. By comparison, alternative (frequentist) methods typically describes uncertainty in predictions using confidence intervals, which are widely used but easy to misinterpret.&lt;/p&gt;
&lt;p&gt;Confidence intervals are calculated so that they will contain the &lt;em&gt;true&lt;/em&gt; value of whatever you are trying to predict with some desired frequency. They provide no information (in the absence of additional assumptions) on how credible various possible results are. The Bayesian equivalent (sometimes called credible intervals) can be drawn anywhere on a predictive distribution. In &lt;a href=&#34;https://mitpress.mit.edu/books/introduction-statistical-decision-theory&#34;&gt;Pratt, Raiffa and Schlaiffer’s textbook&lt;/a&gt; an example is used to highlight this difference:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Imagine the plight of the manager who exclaims, ‘I understand [does he?] the meaning that the demand for XYZ will lie in the interval 973 to 1374 with confidence .90. However, I am particularly interested in the interval 1300 to 1500. What confidence can I place on that interval?’&lt;/em&gt;
&lt;em&gt;Unfortunately, this question cannot be answered. Of course, however, it is possible to give a posterior probability to that particular interval - or any other - based on the sample data and on a codification of the manager’s prior judgements.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And a more succinct description of the same view from &lt;a href=&#34;https://www.weirdfishes.blog/&#34;&gt;Dan Ovando’s fishery statistics blog&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bayesian credible intervals mean what we’d like Frequentist confidence intervals to mean.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seamless-integration-with-decision-analysis&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Seamless Integration with Decision Analysis&lt;/h4&gt;
&lt;p&gt;Following on from the previous point, an analysis that directly describes the probability of any outcome is fully compatible with a decision analysis. After completing a Bayesian analysis, identifying the optimal strategy implied by your model becomes simpler and more understandable.&lt;/p&gt;
&lt;p&gt;As stated in &lt;a href=&#34;https://www.springer.com/gp/book/9780387960982&#34;&gt;James Berger’s (quite theoretical) book on Bayesian statistics&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bayesian analysis and decision theory go rather naturally together, partly because of their common goal of utilizing non-experimental sources of information, and partly because of deep theoretical ties.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;flexible-modelling&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Flexible Modelling&lt;/h4&gt;
&lt;p&gt;So this one is based on a point made in &lt;a href=&#34;https://uk.sagepub.com/en-gb/eur/a-student%E2%80%99s-guide-to-bayesian-statistics/book245409&#34;&gt;Ben Lambert’s book on Bayesian statistics&lt;/a&gt;. It is regarding how modern Bayesian statistics is achieved in practice. The computational methods require some effort to pick up, especially if you do not have experience with programming (though Ben Lambert’s book gives a nice introduction to &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;). However, they can be readily extended to larger and more complex models.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/WiyczarN2XMm4/giphy.gif&#34; alt=&#34;Some Compelling Arguments&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Some Compelling Arguments&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;challenges-difficulties&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Challenges &amp;amp; Difficulties&lt;/h3&gt;
&lt;p&gt;So why would anyone ever &lt;em&gt;not&lt;/em&gt; use Bayesian models when making predictions?&lt;/p&gt;
&lt;div id=&#34;subjectivity&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Subjectivity&lt;/h4&gt;
&lt;p&gt;Perhaps the most common criticism of Bayesian statistics is the requirement for prior models. An initial estimate of uncertainty is a term in Bayes’ theorem - but how can you estimate the extent of variability before you see it in your data? This will surely be completely subjective, so the results will vary depending on who is doing the analysis. This, understandably, doesn’t seem right with a lot of casual enquirers.&lt;/p&gt;
&lt;p&gt;A common response to this accusation is that subjectivity is not an exclusive feature of Bayesian analysis (how about the whole structure of the model you are trying to fit, regardless of your method?) &lt;em&gt;…but&lt;/em&gt; at least Bayesians are required to be explicit about it. Priors are part of the model with no-where to hide (in the code or the reporting) and so they are open to criticism. This point is discussed in &lt;strong&gt;much&lt;/strong&gt; more detail in this paper from &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/gelman_hennig_full_discussion.pdf&#34;&gt;Colombia University&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Priors can contain, as much or as little, information as desired. However, even in instances where you may feel you don’t have any upfront knowledge of a problem, they represent a valuable opportunity for introducing regularisation (which protects against bad predictions due to overfitting). This idea is discussed in detail in &lt;a href=&#34;https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-STAN/McElreath/p/book/9780367139919&#34;&gt;Richard McElreath’s textbook&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computational-requirements&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Computational Requirements&lt;/h4&gt;
&lt;p&gt;In practice, statisticians estimate Bayesian posterior distributions using Markov Chain Monte Carlo (MCMC) sampling algorithms. This approach is slower, more complicated and less informative than standard, independent Monte Carlo sampling. The models that I have worked with during my PhD have taken several hours to finish sampling from, but I have met statisticians whose models run for days or even weeks. Following this, there are checks that need to be completed as there are plenty of things that can go wrong with MCMC.&lt;/p&gt;
&lt;p&gt;My background is in mechanical and civil engineering. In discussions with engineering researchers at conferences I have often been told that the errors and complications they encountered when using MCMC methods had made them believe that Bayesian statistics wasn’t for them. These are challenges that I imagine everyone who has attempted modern Bayesian statistics will have encountered and resolving them can require a deep understanding of your model. Both domain-specific and statistical knowledge is required to help ensure the model you are trying to fit is justified. In addition some programming &lt;em&gt;tricks&lt;/em&gt; like reparameterisation can be of great help to your software, which sometimes needs equivalent, but easier to interpret instructions.&lt;/p&gt;
&lt;p&gt;With all that in mind, when would this ever be worthwhile?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;Regardless of whether you believe we exist in a deterministic universe or not, you will never have perfect state of knowledge describing your problem: uncertainty exists, so we need a sensible and safe way of accounting for it.&lt;/p&gt;
&lt;p&gt;I believe that Bayesian statistics is actually well suited to traditional engineering problems, which are concerned with managing risk when confronted with small, messy datasets and models with plenty of uncertainty. As suggested in the earlier description of confidence intervals, frequentist statistics defines probability based on occurrences of events following a large number of trials or samples. When only limited data is available, Bayesian statistics can shine by comparison.&lt;/p&gt;
&lt;p&gt;Very large datasets may contain enough information to precisely estimate parameters in a model using standard machine learning methods, and so it becomes less worthwhile running simulations to characterise variability. But how common are these big data problems in science and engineering? Sometimes large populations of data are better described as multiple smaller constituent groups, after accounting for key differences between them. Bayesian statistics has a very useful way of managing such problems by structuring models hierarchically. This method allows for &lt;strong&gt;partial pooling of information&lt;/strong&gt; between groups, so that predictions account for the variability and commonality between groups. I will provide a detailed example of this in a future post.&lt;/p&gt;
&lt;p&gt;In conclusion, Bayesian statistics requires (computational and personal) effort to apply. But it provides results that are (usually) more interpretable and closely linked to the questions we want to answer. Whether or not these methods are worth learning of course depend on personal circumstances. I encountered Bayesian statistics during my PhD, and so had plenty of time to read up and I’ve found this to be very rewarding and enjoyable…&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/WPLPEu0GUp41W/giphy.gif&#34; alt=&#34;Boring, isn’t it? Writing, Fitting and Evaluating Bayesian Models All Day….&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Boring, isn’t it? Writing, Fitting and Evaluating Bayesian Models All Day….&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Logistic Regression with Stan</title>
      <link>/post/2020-02-14-bayesian-logistic-regression-with-stan/</link>
      <pubDate>Sat, 15 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-02-14-bayesian-logistic-regression-with-stan/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;Logistic regression is a popular machine learning model. One application of it in an engineering context is quantifying the effectiveness of inspection technologies at detecting damage. This post describes the additional information provided by a Bayesian application of logistic regression (and how it can be implemented using the &lt;code&gt;Stan&lt;/code&gt; probabilistic programming language). Finally, I’ve also included some recommendations for making sense of priors.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;introductions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introductions&lt;/h3&gt;
&lt;p&gt;So there are a couple of key topics discussed here: Logistic Regression, and Bayesian Statistics. Before jumping straight into the example application, I’ve provided some &lt;strong&gt;very&lt;/strong&gt; brief introductions below.&lt;/p&gt;
&lt;div id=&#34;bayesian-inference&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Bayesian Inference&lt;/h4&gt;
&lt;p&gt;At a very high level, Bayesian models quantify (aleatory and epistemic) uncertainty, so that our predictions and decisions take into account the ways in which our knowledge is limited or imperfect. We specify a statistical model, and identify probabilistic estimates for the parameters using a family of sampling algorithms known as Markov Chain Monte Carlo (MCMC). My preferred software for writing a fitting Bayesian models is &lt;a href=&#34;https://mc-stan.org/&#34;&gt;&lt;code&gt;Stan&lt;/code&gt;&lt;/a&gt;. If you are not yet familiar with Bayesian statistics, then I imagine you won’t be fully satisfied with that 3 sentence summary, so I will put together a separate post on the merits and challenges of applied Bayesian inference, which will include much more detail.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logistic-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Logistic Regression&lt;/h4&gt;
&lt;p&gt;Logistic regression is used to estimate the probability of a binary outcome, such as &lt;em&gt;Pass&lt;/em&gt; or &lt;em&gt;Fail&lt;/em&gt; (though it can be extended for &lt;code&gt;&amp;gt; 2&lt;/code&gt; outcomes). This is achieved by transforming a standard regression using the logit function, shown below. The term in the brackets may be familiar to gamblers as it is how odds are calculated from probabilities. You may see &lt;em&gt;logit&lt;/em&gt; and &lt;em&gt;log-odds&lt;/em&gt; used exchangeably for this reason.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Logit (x) = \log\Bigg({\frac{x}{1 - x}}\Bigg)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since the logit function transformed data &lt;em&gt;from&lt;/em&gt; a probability scale, the inverse logit function transforms data &lt;em&gt;to&lt;/em&gt; a probability scale. Therefore, as shown in the below plot, it’s values range from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt;, and this feature is very useful when we are interested the probability of &lt;em&gt;Pass&lt;/em&gt;/&lt;em&gt;Fail&lt;/em&gt; type outcomes.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Inverse\;Logit (x) = \frac{1}{1 + \exp(-x)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Before moving on, some terminology that you may find when reading about logistic regression elsewhere:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a linear regression is combined with a re-scaling function such as this, it is known as a Generalised Linear Model (&lt;strong&gt;GLM&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;The re-scaling (in this case, the logit) function is known as a &lt;strong&gt;link function&lt;/strong&gt; in this context.&lt;/li&gt;
&lt;li&gt;Logistic regression is a &lt;strong&gt;Bernoulli-Logit GLM&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You may be familiar with libraries that automate the fitting of logistic regression models, either in &lt;code&gt;Python&lt;/code&gt; (via &lt;code&gt;sklearn&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X = dataset[&amp;#39;input_variables&amp;#39;], y = dataset[&amp;#39;predictions&amp;#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…or in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_fit &amp;lt;- glm(formula = preditions ~ input_variables,
                 data = dataset, family = binomial(link = &amp;#39;logit&amp;#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-application-probability-of-detection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example Application: Probability of Detection&lt;/h3&gt;
&lt;p&gt;To demonstrate how a Bayesian logistic regression model can be fit (and utilised), I’ve included an example from one of my papers. Engineers make use of data from inspections to understand the condition of structures. Modern inspection methods, whether remote, autonomous or manual application of sensor technologies, are very good. They are generally evaluated in terms of the accuracy and reliability with which they size damage. Engineers never receive perfect information from an inspection, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a crack of &lt;strong&gt;exact&lt;/strong&gt; length &lt;code&gt;30 mm&lt;/code&gt; and &lt;strong&gt;exact&lt;/strong&gt; depth &lt;code&gt;5 mm&lt;/code&gt; at this &lt;strong&gt;exact&lt;/strong&gt; location, or&lt;/li&gt;
&lt;li&gt;There is &lt;strong&gt;definitely&lt;/strong&gt; no damage at this location.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For various reasons, the information we receive from inspections is imperfect and this is something that engineers need to deal with. As a result, providers of inspection services are requested to provide some measure of how good their product is. This typically includes some measure of how accurately damage is sized and how reliable an outcome (detection or no detection) is.&lt;/p&gt;
&lt;p&gt;This example will consider trials of an inspection tool looking for damage of varying size, to fit a model that will predict the probability of detection for any size of damage. Since various forms of damage can initiate in structures, each requiring inspection methods that are suitable, let’s avoid ambiguity and imagine we are only looking for cracks.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/42wQXwITfQbDGKqUP7/giphy.gif&#34; alt=&#34;Detecting Damage: Never 100% Reliable&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Detecting Damage: Never 100% Reliable&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;test-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Test Data&lt;/h4&gt;
&lt;p&gt;For the purposes of this example we will simulate some data. Let’s imagine we have introduced some cracks (of known size) into some test specimens and then arranged for some blind trials to test whether an inspection technology is able to detect them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1008)

N &amp;lt;- 30; lower &amp;lt;- 0; upper &amp;lt;- 10; alpha_true &amp;lt;- -1; beta_true &amp;lt;- 1

depth &amp;lt;- runif(n = N, min = lower, max = upper)

PoD_1D &amp;lt;- function(depth, alpha_1D, beta_1D){
  PoD &amp;lt;- exp(alpha_1D + beta_1D * log(depth)) / (1 + exp(alpha_1D + beta_1D * log(depth)))
  return (PoD)
}

pod_df &amp;lt;- data.frame(depth = depth, det = double(length = N))

for (i in seq(from = 1, to = nrow(pod_df), by = 1)) {
  
  pod_df$det[i] = rbernoulli(n = 1, 
                             p = PoD_1D(depth = pod_df$depth[i], 
                                       alpha_1D = alpha_true, 
                                       beta_1D = beta_true))
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is used to create 30 crack sizes (depths) between 0 and 10 mm. We then use a log-odds model to back calculate a probability of detection for each. This is based on some fixed values for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. In a real trial, these would not be known, but since we are inventing the data we can see how successful our model ends up being in estimating these values.&lt;/p&gt;
&lt;p&gt;The below plot shows the size of each crack, and whether or not it was detected (in our simulation). The smallest crack that was detected was 2.22 mm deep, and the largest undetected crack was 5.69 mm deep. Even so, it’s already clear that larger cracks are more likely to be detected than smaller cracks, though that’s just about all we can say at this stage.&lt;/p&gt;
&lt;p&gt;After fitting our model, we will be able to predict the probability of detection for a crack of any size.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Stan&lt;/code&gt; is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Probabilistic_programming&#34;&gt;probabilistic programming language&lt;/a&gt;. In a future post I will explain why it has been my preferred software for statistical inference throughout my PhD.&lt;/p&gt;
&lt;p&gt;The below is a simple &lt;code&gt;Stan&lt;/code&gt; program to fit a Bayesian Probability of Detection (PoD) model:&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data {

  int &amp;lt;lower = 0&amp;gt; N; // Defining the number of defects in the test dataset
  int &amp;lt;lower = 0, upper = 1&amp;gt; det [N]; // A variable that describes whether each defect was detected [1]or not [0]
  vector &amp;lt;lower = 0&amp;gt; [N] depth; // A variable that describes the corresponding depth of each defect
  
  int &amp;lt;lower = 0&amp;gt; K; // Defining the number of probabilistic predictions required from the model
  vector &amp;lt;lower = 0&amp;gt; [K] depth_pred;
  
}

parameters {
  
  // The (unobserved) model parameters that we want to recover
  real alpha;
  real beta;
  
}

model {

  // A logistic regression model relating the defect depth to whether it will be detected
  det ~ bernoulli_logit(alpha + beta * log(depth));
  
  // Prior models for the unobserved parameters
  alpha ~ normal(0, 1);
  beta ~ normal(1, 1);

}

generated quantities {
  
  // Using the fitted model for probabilistic predicition
  // K posterior predictive distributions will be estimated for a corresponding crack depth
  vector [K] postpred_pr;
  
  for (k in 1:K) {
    
    postpred_pr[k] = inv_logit(alpha + beta * log(depth_pred[k]));
    
  }
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;generated quantities&lt;/code&gt; block will be used to make predictions for the &lt;code&gt;K&lt;/code&gt; values of &lt;code&gt;depth_pred&lt;/code&gt; that we provide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;K &amp;lt;- 50; depth_pred &amp;lt;- seq(from = lower, to = upper, length.out = K)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code generates 50 evenly spaced values, which we will eventually combine in a plot. In some instances we may have specific values that we want to generate probabilistic predictions for, and this can be achieved in the same way.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Fitting the model&lt;/h4&gt;
&lt;p&gt;Data can be pre-processed in any language for which a &lt;code&gt;Stan&lt;/code&gt; interface has been developed. This includes, &lt;code&gt;R&lt;/code&gt;, &lt;code&gt;Python&lt;/code&gt;, and &lt;code&gt;Julia&lt;/code&gt;. In this example we will use &lt;code&gt;R&lt;/code&gt; and the accompanying package, &lt;code&gt;rstan&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our &lt;code&gt;Stan&lt;/code&gt; model is expecting data for three variables: &lt;strong&gt;N&lt;/strong&gt;, &lt;strong&gt;det&lt;/strong&gt;, &lt;strong&gt;depth&lt;/strong&gt;, &lt;strong&gt;K&lt;/strong&gt; and &lt;strong&gt;depth_pred&lt;/strong&gt; and &lt;code&gt;rstan&lt;/code&gt; requires this in the form of a list.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Results&lt;/h4&gt;
&lt;p&gt;Once we have our data, and are happy with our model, we can set off the Markov chains. There are plenty of opportunities to control the way that the &lt;code&gt;Stan&lt;/code&gt; algorithm will run, but I won’t include that here, rather we will mostly stick with the default arguments in &lt;code&gt;rstan&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)

PoD_samples &amp;lt;- sampling(object = PoD_model, 
                        data = list(N = N, det = pod_df$det, depth = pod_df$depth,
                                    K = K, depth_pred = depth_pred), 
                        seed = 1008)
## 
## SAMPLING FOR MODEL &amp;#39;7e5f8dcf245c90341e1fcbe2d195277e&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.087 seconds (Warm-up)
## Chain 1:                0.09 seconds (Sampling)
## Chain 1:                0.177 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;7e5f8dcf245c90341e1fcbe2d195277e&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.113 seconds (Warm-up)
## Chain 2:                0.086 seconds (Sampling)
## Chain 2:                0.199 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;7e5f8dcf245c90341e1fcbe2d195277e&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 0 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.08 seconds (Warm-up)
## Chain 3:                0.085 seconds (Sampling)
## Chain 3:                0.165 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;7e5f8dcf245c90341e1fcbe2d195277e&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 0 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.091 seconds (Warm-up)
## Chain 4:                0.101 seconds (Sampling)
## Chain 4:                0.192 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:I’ve not included any detail here on the checks we need to do on our samples. There are some common challenges associated with MCMC methods, each with plenty of associated guidance on how to diagnose and resolve them. For now, let’s assume everything has gone to plan.&lt;/p&gt;
&lt;p&gt;Now, there are a few options for extracting samples from a stanfit object such as &lt;code&gt;PoD_samples&lt;/code&gt;, including &lt;code&gt;rstan::extract()&lt;/code&gt;. However, these usually require a little post-processing to get them into a tidy format - no big deal, but a hassle I’d rather avoid. That’s why I like to use the &lt;code&gt;ggmcmc&lt;/code&gt; &lt;a href=&#34;https://cran.r-project.org/web/packages/ggmcmc/&#34;&gt;package&lt;/a&gt;, which we can use to create a data frame that specifies the iteration, parameter value and chain associated with each data point:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmcmc)

PoD_extracted_samples &amp;lt;- ggs(S = PoD_samples)

head(x = PoD_extracted_samples, n = 5)
## # A tibble: 5 x 4
##   Iteration Chain Parameter   value
##       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;
## 1         1     1 alpha      0.0975
## 2         2     1 alpha     -0.498 
## 3         3     1 alpha     -1.12  
## 4         4     1 alpha     -1.36  
## 5         5     1 alpha     -1.54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have sampled from a 2-dimensional posterior distribution of the unobserved parameters in the model: &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. Below is a density plot of their corresponding marginal distributions based on the &lt;code&gt;1000&lt;/code&gt; samples collected from each of the &lt;code&gt;4&lt;/code&gt; Markov chains that have been run.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So our estimates are beginning to converge on the values that were used to generate the data, but this plot also shows that there is still plenty of uncertainty in the results. Unlike many alternative approaches, Bayesian models account for the statistical uncertainty associated with our limited dataset - remember that we are estimating these values from 30 trials. These results describe the possible values of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; in our model that are consistent with the limited available evidence. If more data was available, we could expect the uncertainty in our results to decrease. I think there are some great reasons to keep track of this statistical (sometimes called &lt;em&gt;epistemic&lt;/em&gt;) uncertainty - a primary example being that we should be interested in how confident our predictive models are in their own results!
…but I’ll leave it at that for now, and try to stay on topic.&lt;/p&gt;
&lt;p&gt;How do we know what do these estimates of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; mean for the PoD (what we are ultimately interested in)?
We can check this using the posterior predictive distributions that we have (thanks to the &lt;code&gt;generated quantities&lt;/code&gt; block of the &lt;code&gt;Stan&lt;/code&gt; program).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One thing to note from these results is that the model is able to make much more confident predictions for larger crack sizes. The increased uncertainty associated with shallow cracks reflects the lack of data available in this region - this could be useful information for a decision maker!&lt;/p&gt;
&lt;p&gt;There are only 3 trials in our dataset considering cracks shallower than 3 mm (and only 1 for crack depths &lt;code&gt;&amp;lt; 2&lt;/code&gt; mm). If we needed to make predictions for shallow cracks, this analysis could be extended to quantify the value of future tests in this region.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-thought-where-did-those-priors-come-from-and-are-they-any-good&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Final Thought: Where Did Those Priors Come From and Are They Any Good?&lt;/h4&gt;
&lt;p&gt;There are many approaches for specifying prior models in Bayesian statistics. &lt;em&gt;Weakly informative&lt;/em&gt; and &lt;em&gt;MaxEnt&lt;/em&gt; priors are advocated by various authors. Unfortunately, &lt;em&gt;Flat Priors&lt;/em&gt; are sometimes proposed too, particularly (but not exclusively) in older books. A flat prior is a wide distribution - in the extreme this would be a uniform distribution across all real numbers, but in practice distribution functions with very large variance parameters are sometimes used. In either case, a very large range prior of credible outcomes for our parameters is introduced the model. This may sound innocent enough, and in many cases could be harmless.&lt;/p&gt;
&lt;p&gt;Flat priors have the appeal of describing a state of complete uncertainty, which we may believe we are in before seeing any data - but is this really the case?&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/UgM7H8OEmf4mQ/giphy.gif&#34; alt=&#34;Prior Expectations: Can We Do Better?&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Prior Expectations: Can We Do Better?&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Suppose you are using Bayesian methods to model the speed of some athletes. Even before seeing any data, there is some information that we can build into the model. For instance, we can discount negative speeds. We also wouldn’t need to know anything about the athletes to know that they would not be travelling faster than the speed of light. This may sound facetious, but flat priors are implying that we should treat all outcomes as equally likely. In fact, there are some cases where flat priors cause models to require large amounts of data to make good predictions (meaning we are failing to take advantage of Bayesian statistics ability to work with limited data).&lt;/p&gt;
&lt;p&gt;In this example, we would probably just want to constrain outcomes to the range of metres per second, but the amount of information we choose to include is ultimately a modelling choice. Another helpful feature of Bayesian models is that the priors are part of the model, and so must be made explicit - fully visible and ready to be scrutinised.&lt;/p&gt;
&lt;p&gt;A common challenge, which was evident in the above PoD example, is lacking an intuitive understanding of the meaning of our model parameters. Here &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; required prior models, but I don’t think there is an obvious way to relate their values to the result we were interested in. They are linear regression parameters on a log-odds scale, but this is then transformed into a probability scale using the logit function.&lt;/p&gt;
&lt;p&gt;This problem can be addressed using a process known as &lt;strong&gt;Prior Predictive Simulation&lt;/strong&gt;, which I was first introduced to in &lt;a href=&#34;https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-STAN/McElreath/p/book/9780367139919&#34;&gt;Richard McElreath’s fantastic book&lt;/a&gt;. This involves evaluating the predictions that our model would make, based only on the information in our priors. Relating our predictions to our parameters provides a clearer understanding of the implications of our priors.&lt;/p&gt;
&lt;p&gt;Back to our PoD parameters - both &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; can take positive or negative values, but I could not immediately tell you a sensible range for them. Based on our lack of intuition it may be tempting to use a variance for both, right? Well, before making that decision, we can always simulate some predictions from these priors. The below code is creating a data frame of prior predictions for the PoD (&lt;code&gt;PoD_pr&lt;/code&gt;) for many possible crack sizes.
&lt;span class=&#34;math display&#34;&gt;\[
\alpha \sim N(\mu_{\alpha}, \sigma_{\alpha})
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
\beta \sim N(\mu_{\beta}, \sigma_{\beta})
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(from = min_depth, to = max_depth, length.out = N_samples)
prPrSim_df &amp;lt;- data.frame(depth = x)

for (i in seq(from = 1, to = nrow(prPrSim_df), by = 1)) {
  
  alpha = rnorm(n = N_samples, mean = mu_alpha, sd = sigma_alpha)
  beta = rnorm(n = N_samples, mean = mu_beta, sd = sigma_beta)
  prPrSim_df$PoD_pr[i] &amp;lt;- exp(alpha + beta * log(prPrSim_df$depth[i]))/(1 + exp(alpha + beta * log(prPrSim_df$depth[i])))

}

head(prPrSim_df)
##        depth       PoD_pr
## 1 0.00000000 0.000000e+00
## 2 0.01001001 4.085619e-05
## 3 0.02002002 5.966123e-02
## 4 0.03003003 4.766970e-05
## 5 0.04004004 4.532144e-03
## 6 0.05005005 2.997338e-03&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we can visualise the information contained within our priors for a couple of different cases.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our wide, supposedly &lt;em&gt;non&lt;/em&gt;-informative priors result in some pretty useless predictions. I’ve suggested some more sensible priors that suggest that larger cracks are more likely to be detected than small cracks, without overly constraining our outcome (see that there is still prior credible that very small cracks are detected reliably and that very large cracks are often missed).&lt;/p&gt;
&lt;p&gt;Why did our predictions end up looking like this?&lt;/p&gt;
&lt;p&gt;Borrowing from McElreath’s explanation, it’s because &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; are linear regression parameters on a log-odds (logit) scale. Since we are estimating a PoD we end up transforming out predictions onto a probability scale. Flat priors for our parameters imply that extreme values of log-odds are credible. All that prior credibility of values &lt;code&gt;&amp;lt; - 3&lt;/code&gt; and &lt;code&gt;&amp;gt; 3&lt;/code&gt; ends up getting concentrated at probabilities near &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;. I think this is a really good example of flat priors containing a lot more information than they appear to.&lt;/p&gt;
&lt;p&gt;I’ll end by directing you towards some additional (generally non-technical) discussion of choosing priors, written by the &lt;code&gt;Stan&lt;/code&gt; development team &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;(link)&lt;/a&gt;. It provides a definition of &lt;em&gt;weakly informative priors&lt;/em&gt;, some words of warning against &lt;em&gt;flat priors&lt;/em&gt; and more general detail than this humble footnote.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-14-bayesian-logistic-regression-with-stan_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Inspection Planning of Hazardous Locations Using a Value of Information Analysis</title>
      <link>/publication/ifed/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/publication/ifed/</guid>
      <description>&lt;!---
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;



(&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
---&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Fatigue Modelling</title>
      <link>/publication/ipw/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/ipw/</guid>
      <description>&lt;!---
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;



(&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
---&gt;
</description>
    </item>
    
    <item>
      <title>Animating Plots</title>
      <link>/post/animating-plots/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      <guid>/post/animating-plots/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;There are many instances where it may be useful to animate graphical representations of data, perhaps to add an additional dimension to a plot. The below example builds a cumulative map of car accidents in the UK using some of the functionality of the &lt;code&gt;gganimate&lt;/code&gt; &lt;a href=&#34;https://cran.r-project.org/web/packages/gganimate&#34;&gt;package&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;making-moving-plots-with-gganimate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Making Moving Plots with &lt;code&gt;gganimate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Graphics made using the &lt;code&gt;ggplot2&lt;/code&gt; package are already extremely customisable. They can be further enhanced using some of the &lt;a href=&#34;http://ggplot2-exts.org/gallery/&#34;&gt;extensions that have been developed&lt;/a&gt;. These include providing access to new themes, as well as entirely new functionality.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;gganimate&lt;/code&gt; allows for the animation of existing ggplot graphics. Once installed, we can load both packages (&lt;code&gt;ggplot2&lt;/code&gt; is included as part of the &lt;code&gt;tidyverse&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate); library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The example uses a car accident dataset that I found on &lt;a href=&#34;https://www.kaggle.com/silicon99/dft-accident-data/data#&#34;&gt;Kaggle&lt;/a&gt;. Here are the first few rows of the variables that we’re interested in:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(Accidents_Dec2015 %&amp;gt;% 
       dplyr::select(Date, Longitude, Latitude, Number_of_Casualties, Accident_Severity))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Date Longitude Latitude Number_of_Casualties Accident_Severity
## 1 2015-12-01 -0.155880 51.48959                    1            Slight
## 2 2015-12-01 -0.200271 51.49262                    1            Slight
## 3 2015-12-03 -0.210643 51.49997                    2            Slight
## 4 2015-12-03 -0.156754 51.49293                    1            Slight
## 5 2015-12-03 -0.159124 51.50205                    1            Slight
## 6 2015-12-04 -0.197452 51.49104                    1            Slight&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot the coordinates using a map of the UK included in &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;UK_coords &amp;lt;- ggplot2::map_data(map = &amp;#39;world&amp;#39;, region = &amp;#39;UK&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before animating we need to create a ggplot that we will work from.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;accidents_plot &amp;lt;- ggplot(data = UK_coords)+
  geom_polygon(mapping = aes(x = long, y = lat, group = group), col = &amp;#39;black&amp;#39;, fill = NA)+
  theme_void(base_size = 12, base_family = &amp;#39;Bahnschrift&amp;#39;)+
  geom_point(data = Accidents_Dec2015, 
             mapping = aes(x = Longitude, y = Latitude, col = as.factor(Accident_Severity), 
                           alpha = as.factor(Accident_Severity), size = Number_of_Casualties,
             group = seq_len(length.out = nrow(Accidents_Dec2015))))+
  theme(legend.position = &amp;#39;right&amp;#39;)+
  scale_size_continuous(breaks = c(1, 3, 9))+
  scale_color_manual(values = c(&amp;#39;firebrick&amp;#39;, &amp;#39;forestgreen&amp;#39;, &amp;#39;steelblue&amp;#39;))+
  scale_alpha_manual(values = c(0.4, 0.2, 0.1), guide = &amp;#39;none&amp;#39;)+
  guides(col = guide_legend(title = element_blank(), ncol = 1),
         size = guide_legend(title = element_text(&amp;#39;Casualties&amp;#39;, size = 10), ncol = 1, alpha = 0.4))

accidents_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-04-animating-plots_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can now add some functions from &lt;code&gt;gganimate&lt;/code&gt;, which will describe how and saving as a new variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

accidents_plot &amp;lt;- accidents_plot +
  transition_time(time = Date)+
  enter_grow()+
  shadow_mark()+
  ggtitle(label = &amp;#39;UK Car Accidents in December 2015&amp;#39;, subtitle = &amp;#39;Date : {frame_time}&amp;#39;)+
  labs(caption = &amp;#39;Data from Kaggle: https://www.kaggle.com/silicon99/dft-accident-data/data |  @Domenic_DF&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;transition_time()&lt;/code&gt; requires specification of a time variable that the plot will display sequentially. As shown above, this animation will transition through values of &lt;code&gt;Date&lt;/code&gt;. There are many more options that allow for animation across different data types in different ways.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;shadow_mark()&lt;/code&gt; has been added to keep accidents from previous dates. Again, there are various methods of showing data from previous states.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;enter_grow()&lt;/code&gt; means that when new data first appear on the plot, they will emerge by growing into their final size.&lt;/p&gt;
&lt;p&gt;Some of these additional options are detailed &lt;a href=&#34;https://cran.r-project.org/web/packages/gganimate&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this case, &lt;code&gt;transition_length&lt;/code&gt; and &lt;code&gt;state_length&lt;/code&gt; describe the &lt;strong&gt;relative&lt;/strong&gt; amount of time spent displaying the current state, and transitioning to the next state.&lt;/p&gt;
&lt;p&gt;Regardless of the transition function selected, the best way to create the moving plot is to use the &lt;code&gt;animate&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animate(plot = accidents_plot, fps = 20, duration = 30, end_pause = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;animate()&lt;/code&gt; function requires us to specify the plot (to be animated), but includes many additional arguments not all of which are detailed above.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fps&lt;/code&gt; is the frames per second, &lt;code&gt;duration&lt;/code&gt; is the length of the animation (in seconds), and &lt;code&gt;end_pause&lt;/code&gt; is the length of time that the final frame is held for (in number of frames.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-animation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Final Animation&lt;/h3&gt;
&lt;p&gt;I tried a few alternatives here. In this case each state has quite a few points and so I wanted it to be held for a reasonable amount of time. The trade-off here is the number of frames (and associated processing time and file size). The below allocates approximately &lt;code&gt;1&lt;/code&gt; second per day and results in a total of 600 frames for the animation. On my (ageing) laptop this required approximately 4 minutes to render.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2019-06-04-animating-plots_files/UK_Car_Acc_Dec_2015.gif&#34; alt=&#34;Animated Map&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Animated Map&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;thoughts-on-the-animation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Thoughts on the Animation&lt;/h3&gt;
&lt;p&gt;What does the animation tell us that the stationary plot doesn’t?&lt;/p&gt;
&lt;p&gt;The final frame is pretty much identical, but the transitions will show when the accidents occurred. From viewing the animation there doesn’t appear to be a clear time when accidents were more frequent. We can check this with an additional plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Accidents_Dec2015 %&amp;gt;% 
     dplyr::select(Date, Number_of_Casualties, Accident_Severity) %&amp;gt;% 
     ggplot(mapping = aes(x = Date))+
        geom_bar(stat = &amp;#39;count&amp;#39;, fill = &amp;#39;grey80&amp;#39;)+
        facet_wrap(facets = ~ Accident_Severity, scales = &amp;#39;free&amp;#39;)+
        theme_ddf_light()+
        coord_flip()+
        theme(axis.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-04-animating-plots_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What isn’t shown in the data is the number of cars that were on the road at the time, so it could be that there were a higher proportion of accidents between the &lt;code&gt;24&lt;/code&gt;th and &lt;code&gt;31&lt;/code&gt;st December - but that will have to remain speculation for now.&lt;/p&gt;
&lt;p&gt;One tip that I picked up from the &lt;a href=&#34;https://github.com/thomasp85/gganimate/&#34;&gt;package developer&lt;/a&gt; was the need to group data in the geom to avoid new points &lt;em&gt;travelling&lt;/em&gt; from the location of other points. Given the context of the plot, that could have been interpreted as the same vehicles having accidents all over the UK. I’m glad that I was able to avoid this ambiguity in the plot.&lt;/p&gt;
&lt;p&gt;In conclusion, I think the animated plot looks cool, but it is perhaps a little gimmicky for this particular application. The same information is contained in the two static plots in this post. However, I hope this has content serves as a helpful introduction to how the &lt;code&gt;gganimate&lt;/code&gt; package can automate animated graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional Resources&lt;/h3&gt;
&lt;p&gt;This example is certainly not exhaustive and there are many additional tweaks available to further customise an animation. I have personally found the below resources to be particularly helpful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The official &lt;a href=&#34;https://cran.r-project.org/web/packages/gganimate/vignettes/gganimate.html&#34;&gt;beginner’s guide&lt;/a&gt; to &lt;code&gt;gganimate&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A tutorial from the &lt;a href=&#34;https://goodekat.github.io/presentations/2019-isugg-gganimate-spooky/slides.html&#34;&gt;ISU Graphics Group&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Wordclouds</title>
      <link>/post/31.05.19-wordcloud/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      <guid>/post/31.05.19-wordcloud/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TLDR&lt;/h3&gt;
&lt;p&gt;Wordclouds can be used to produce a neat summary of text and can readily be produced in R. This is a simple example based on a recent conferene paper.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;summarising-the-content-of-a-conference-paper&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summarising the content of a conference paper&lt;/h3&gt;
&lt;p&gt;There is an &lt;a href=&#34;https://cran.r-project.org/web/packages/wordcloud/index.html&#34;&gt;R package dedicated to creating wordclouds&lt;/a&gt;, so I’ve started by loading this, along with the &lt;strong&gt;tidyverse&lt;/strong&gt; (for standard data manipulation) and &lt;strong&gt;tidytext&lt;/strong&gt; (for some help processing the contents of the paper).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wordcloud); library(tidyverse); library(tidytext)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The wordcloud package creates a graphic of words that appear in some specified text. The size of the word is proprtional to its frequency in the text
R can read text from a local file, as shown below, or from a website.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We can read a text file using &amp;#39;readLines&amp;#39; and we can select a file interactively using &amp;#39;file.choose&amp;#39;
# Both of these are Base R functions
paper &amp;lt;- readLines(file.choose())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ‘paper’ variable is currently as list of individual lines, as we can see when viewing one of its elements:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paper[2])
## [1] &amp;quot;Application of MCMC Sampling to Account for Variability and Dependency&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;tidytext&lt;/strong&gt; helps get this into a friendlier format allowing us to count the occirence of each word.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paper_tbl &amp;lt;- as_tibble(paper) %&amp;gt;% 
  tidytext::unnest_tokens(word, value) %&amp;gt;% 
  dplyr::filter(is.na(as.numeric(word))) %&amp;gt;% 
  count(word)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since I expected words like ‘the’ and ‘of’ are likely to feature a lot in the text, I wanted to be able to remove them. I initally used &lt;strong&gt;dplyr&lt;/strong&gt; to set up a variable that would allow me to filter out shorter words, based on some threshold…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;minLength &amp;lt;- 4

paper_tbl &amp;lt;- paper_tbl %&amp;gt;% 
  mutate(check = case_when(nchar(word) &amp;lt; minLength ~ 0,
                           nchar(word) &amp;gt;= minLength ~ 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But then I learnt about &lt;a href=&#34;https://en.wikipedia.org/wiki/Stop_words&#34;&gt;stopwords&lt;/a&gt; and made use of the database that &lt;strong&gt;tidytext&lt;/strong&gt; conveniently provides, before removing them from the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paper_tbl &amp;lt;- paper_tbl %&amp;gt;%  
 anti_join(tidytext::get_stopwords(language = &amp;#39;en&amp;#39;, source = &amp;#39;stopwords-iso&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before sending this directly into the wordcloud function, we can review the current state of the data, either as a table…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(x = paper_tbl %&amp;gt;% 
       arrange(desc(x = n)), n = 10)
## # A tibble: 10 x 2
##    word           n
##    &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;
##  1 model         58
##  2 models        27
##  3 fatigue       25
##  4 data          24
##  5 parameters    24
##  6 bayesian      22
##  7 posterior     18
##  8 crack         17
##  9 growth        14
## 10 priors        12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…or as a simple plot (in either case I’m only interested in the most frequent words for now) …&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(paper_tbl %&amp;gt;% 
         arrange(desc(n)) %&amp;gt;% 
         dplyr::filter(n &amp;gt;= 12))+
  geom_col(mapping = aes(x = word, y = n))+
  theme_minimal()+ theme(axis.text.x = element_text(angle = 90), 
                         axis.title.x = element_blank())+
  labs(y = &amp;#39;count&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/31.05.19-Wordcloud_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One thing that is apparent from the above summaries is that we have not dealt with plurals from the data, i.e. ‘model’ and ‘models’ will be treated as two different words, with their own count. I’ve not found a neat way to combine these, but a manual solution with regular expressions (such as &lt;em&gt;grepl&lt;/em&gt;, &lt;em&gt;!grepl&lt;/em&gt;, etc.) would be simple, though not very elegant. I decided to leave plurals as they are.&lt;/p&gt;
&lt;p&gt;Finally, time to ask the wordcloud function to read and plot our data. There are some useful arguments to experiment with here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;min.freq&lt;/strong&gt; and &lt;strong&gt;max.words&lt;/strong&gt; set boundaries for how populated the wordcloud will be&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;random.order&lt;/strong&gt; will put the largest word in the middle if set to FALSE&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rot.per&lt;/strong&gt; is the fraction of words that will be rotated in the graphic&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, the words are arranged stochastically somehow, and so for a repeatable graphic we need to specify a seed value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1008) 

wordcloud(words = paper_tbl$word, freq = paper_tbl$n, 
          min.freq = 4, max.words = 100, random.order = FALSE, rot.per = 0.25,
          colors = brewer.pal(n = 8, name = &amp;#39;Paired&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/31.05.19-Wordcloud_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you’re not familiar with the colour palettes, the below line will ask R to display them for you:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RColorBrewer::display.brewer.all()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, some links to more information regarding the packages introduced here, both of which are available on CRAN:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/wordcloud/index.html&#34;&gt;wordcloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html&#34;&gt;tidytext&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
